# Assignment 1: Classifier By Hand


In this assignment, you learn step by step how to code a binary classifier by hand! 

Don't worry, it will be guided through.

## Introduction: calorimeter showers
A calorimeter in the context of experimental particle physics is a sub-detector aiming at measuring the energy of incoming particles. At CERN Large Hadron Collider, the giant multipurpose detectors [ATLAS](https://atlas.cern/Discover/Detector/Calorimeter) and CMS are both equipped with electromagnetic and hadronic calorimeters. The electronic calorimeter, as its name indicates, is measuring the energy of incoming electrons. It is a destructive method: the energetic electron entering the calorimeter will interact with its dense material via the electromagnetic force. It eventually results in the generation of a shower of particles (electromagnetic shower), with a characteristic average depth and width. The depth is along the direction of the incoming particle and the width is the dimension perpendicular to it.

Problem? There can be noissy signals in electromagnetic calorimeters that are generated by hadrons, not electrons. 

Your mission is to help physicists by coding a classifier to select electron-showers (signal) from hadron-showers (background). 

To this end, you are given a dataset of shower characterists from previous measurments where the incoming particle was known. The main features are the depth and the width. 

```{figure} ../images/a01_showers.png
---
  name: a01_showers
  width: 60%
---
 .  Visualization of an electron shower (left) and hadron shower (right).  
 <sub>From [ResearchGate](https://www.researchgate.net/figure/The-different-character-of-electromagneticgamma-and-hadronic-showers-19_fig2_270824497)</sub>
```

```{figure} ../images/a01_showers_distribs.png
---
  name: a01_showers_distribs
  width: 100%
---
 .  Hadron showers are on average longer in the direction of the incoming hadron (depth) and large in the transverse direction (width).  
 <sub>Plot made using dataset.</sub>
```
````{margin}
```{admonition} Dataset
Find the repository on GDrive [here](https://drive.google.com/drive/folders/1hVq0gnDeQvQ7dIvl0bPTyJn9DGMscqwc?usp=sharing).
```
````
## 1. Get the Data
Download the dataset and put it on your GDrive. Open a new Jupyter-notebook. To mount your drive:
```python
from google.colab import drive
drive.mount('/content/gdrive')
```

__1.1 Get and load the data__  
Read the dataset into a dataframe `df`. What are the columns? Which column stores the labels (targets)?

__1.2 How many samples are there?__  

## 2. Feature Scaling

__2.1 Explain with math__  
Before coding, explain using the mathematical expressions seen in Lecture 3 on Logistic Regression why the gradient descent is likely to diverge if features are not rescaled. 
_Hints:_
_* Recall that the $\boldsymbol{\theta}$ parameters are usually initialized with random numbers from 0 and 1 (hint again: positive)._
_* Recall the shape of the sigmoid and what it would imply on the cost function, especially for background samples._

__2.2 Standarization__  
Create for each input feature an extra column in the dataframe to rescale it to a distribution of zero-mean and unit-variance. To see statistical information on a dataframe, a convenient method is:
```python
df.describe()
```
We will take $x_1$ and $x_2$ in the order of the dataframe's columns. By searching in the documentation for methods retrieving the mean and standard deviation, complete the following code:
```python
MEAN_X1  =
SIGMA_X1 =   
MEAN_X2  =
SIGMA_X2 =  

df['shower_depth_scaled'] = 
df['shower_width_scaled'] = 
```

_Hint: Recall Definition {prf:ref}`defStandardization`._

Check your results by calling `df.describe()` on the updated dataframe.

## 3. Data Prep
Let's get 


## 4. Useful Functions



