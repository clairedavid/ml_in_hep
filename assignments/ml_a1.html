
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Assignment 1: Classifier By Hand &#8212; Machine Learning in Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning in Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning in Particle Physics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/learningoutcomes.html">
   Learning outcomes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/jupyter.html">
   JupyterHub for class
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/trailer.html">
   1. Course Trailer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_hep.html">
     From detectors to publications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_mldef.html">
     What is Machine Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_pb.html">
     Which problems does ML solve?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/warmup_1D.html">
   2. Warm up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_linRegGD.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_linRegGDmulti.html">
     Multivariate linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_learningR.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_practice.html">
     Gradient Descent in practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/class_algs.html">
   3. Classification algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_logReg.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_costF.html">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_reg.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_biasV.html">
     Performance Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/BDTs.html">
   4. Decision Trees and Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_def.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_forest.html">
     Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_boosting.html">
     What is boosting?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week1/review_week1.html">
   5. Review Week 1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN1.html">
   6. Neural Networks Part I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_motivations.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_modelRep.html">
     Model Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_activationF.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_feedforward.html">
     Feedforward Propagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN2.html">
   7. Neural Networks Part II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_costF.html">
     Neural Network Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_init.html">
     Initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/DL.html">
   8. Towards Deep Learning Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_stochGD.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_adaptLR.html">
     Varying the Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_paramHyper.html">
     Hyperparameters in DL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_trainNN.html">
     Let’s train our NN!
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/CNN.html">
   9. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_architecture.html">
     Architecture of a CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_hyperparameters.html">
     Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_regMethods.html">
     Regularization Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_neutrinoReco.html">
     Application in Neutrino Physics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week2/review_week2.html">
   10. Review Week 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/unsupervised_learning.html">
   11. Unsupervised learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_motiv.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_relevance.html">
     Relevance and examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_k-Means.html">
     k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_dimRed.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/PCA_AD.html">
   12. PCA and Anomaly Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_PCA.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_autoEncoder.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_VAE_for_AD.html">
     Variational Autoencoder for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ML_BigData.html">
   13. ML in Big Data &amp; Strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_7Vs.html">
     The 7V’s of Big Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_preproc.html">
     Data Preprocessing Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_chooseAlgo.html">
     How to Choose an Optimization Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ethics_outlook.html">
   14. Ethics in ML &amp; Outlook
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_outlook_1.html">
     The Ethics in ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_outlook_2.html">
     Machine Learning Today
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week3/projects_exam.html">
   15. Project presentations &amp; Exam
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regression.html">
   1. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_forestry.html">
   2. ‘Forestree’ with LHC collisions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_nn_by_hand.html">
   3. Neural Network By Hand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_class_game.html">
   4. Classification Contest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t05_anomaly_detection.html">
   5. Anomaly Detection
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fassignments/ml_a1.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/assignments/ml_a1.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-calorimeter-showers">
   Introduction: calorimeter showers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#get-the-data">
   1. Get the Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-scaling">
   2. Feature Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-prep">
   3. Data Prep
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataframes-to-numpy">
   4. DataFrames to Numpy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#useful-functions">
   5. Useful Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classifier">
   6. Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-cost-versus-epochs">
   7. Plot cost versus epochs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance">
   8. Performance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#x-bonus-decision-boundaries">
   X. BONUS: Decision Boundaries
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Assignment 1: Classifier By Hand</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction-calorimeter-showers">
   Introduction: calorimeter showers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#get-the-data">
   1. Get the Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-scaling">
   2. Feature Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-prep">
   3. Data Prep
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataframes-to-numpy">
   4. DataFrames to Numpy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#useful-functions">
   5. Useful Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classifier">
   6. Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-cost-versus-epochs">
   7. Plot cost versus epochs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance">
   8. Performance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#x-bonus-decision-boundaries">
   X. BONUS: Decision Boundaries
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="assignment-1-classifier-by-hand">
<h1>Assignment 1: Classifier By Hand<a class="headerlink" href="#assignment-1-classifier-by-hand" title="Permalink to this headline">#</a></h1>
<p>In this assignment, you learn step by step how to code a binary classifier by hand!</p>
<p>Don’t worry, it will be guided through.</p>
<section id="introduction-calorimeter-showers">
<h2>Introduction: calorimeter showers<a class="headerlink" href="#introduction-calorimeter-showers" title="Permalink to this headline">#</a></h2>
<p>A calorimeter in the context of experimental particle physics is a sub-detector aiming at measuring the energy of incoming particles. At CERN Large Hadron Collider, the giant multipurpose detectors <a class="reference external" href="https://atlas.cern/Discover/Detector/Calorimeter">ATLAS</a> and CMS are both equipped with electromagnetic and hadronic calorimeters. The electronic calorimeter, as its name indicates, is measuring the energy of incoming electrons. It is a destructive method: the energetic electron entering the calorimeter will interact with its dense material via the electromagnetic force. It eventually results in the generation of a shower of particles (electromagnetic shower), with a characteristic average depth and width. The depth is along the direction of the incoming particle and the width is the dimension perpendicular to it.</p>
<p>Problem? There can be noissy signals in electromagnetic calorimeters that are generated by hadrons, not electrons.</p>
<p>Your mission is to help physicists by coding a classifier to select electron-showers (signal) from hadron-showers (background).</p>
<p>To this end, you are given a dataset of shower characterists from previous measurments where the incoming particle was known. The main features are the depth and the width.</p>
<figure class="align-default" id="a01-showers">
<a class="reference internal image-reference" href="../_images/a01_showers.png"><img alt="../_images/a01_showers.png" src="../_images/a01_showers.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-text">Visualization of an electron shower (left) and hadron shower (right).<br />
<sub>From <a class="reference external" href="https://www.researchgate.net/figure/The-different-character-of-electromagneticgamma-and-hadronic-showers-19_fig2_270824497">ResearchGate</a></sub></span><a class="headerlink" href="#a01-showers" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Hadron showers are on average longer in the direction of the incoming hadron (depth) and large in the transverse direction (width).</p>
<figure class="align-default" id="a01-showers-distribs">
<a class="reference internal image-reference" href="../_images/a01_showers_distribs.png"><img alt="../_images/a01_showers_distribs.png" src="../_images/a01_showers_distribs.png" style="width: 100%;" /></a>
</figure>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition-dataset admonition">
<p class="admonition-title">Dataset</p>
<p>Find the repository on GDrive <a class="reference external" href="https://drive.google.com/drive/folders/1hVq0gnDeQvQ7dIvl0bPTyJn9DGMscqwc?usp=sharing">here</a>.</p>
</div>
</aside>
</section>
<section id="get-the-data">
<h2>1. Get the Data<a class="headerlink" href="#get-the-data" title="Permalink to this headline">#</a></h2>
<p>Download the dataset and put it on your GDrive. Open a new Jupyter-notebook. To mount your drive:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/gdrive&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>1.1 Get and load the data</strong><br />
Read the dataset into a dataframe <code class="docutils literal notranslate"><span class="pre">df</span></code>. What are the columns? Which column stores the labels (targets)?</p>
<p><strong>1.2 How many samples are there?</strong></p>
<p>For the following, import the NumPy and pandas libraries:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</section>
<section id="feature-scaling">
<h2>2. Feature Scaling<a class="headerlink" href="#feature-scaling" title="Permalink to this headline">#</a></h2>
<p><strong>2.1 Explain with math</strong><br />
Before coding, explain using the mathematical expressions seen in Lecture 3 on Logistic Regression why the gradient descent is likely to diverge if features are not rescaled.</p>
<p><em>Hint 1: recall that the <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> parameters are usually initialized with random numbers from 0 and 1.</em><br />
<em>Hint 1.1: they are positive…</em><br />
<em>Hint 2: recall the shape of the sigmoid and what it would imply on the cost function, especially for background samples.</em></p>
<p><strong>2.2 Standarization</strong><br />
Create for each input feature an extra column in the dataframe to rescale it to a distribution of zero-mean and unit-variance. To see statistical information on a dataframe, a convenient method is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
<p>We will take <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> in the order of the dataframe’s columns. By searching in the documentation for methods retrieving the mean and standard deviation, complete the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MEAN_X1</span>  <span class="o">=</span>
<span class="n">SIGMA_X1</span> <span class="o">=</span>   
<span class="n">MEAN_X2</span>  <span class="o">=</span>
<span class="n">SIGMA_X2</span> <span class="o">=</span>  

<span class="n">df</span><span class="p">[</span><span class="s1">&#39;shower_depth_scaled&#39;</span><span class="p">]</span> <span class="o">=</span> 
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;shower_width_scaled&#39;</span><span class="p">]</span> <span class="o">=</span> 
</pre></div>
</div>
<p><em>Hint: recall <a class="reference internal" href="../week1/warmup_1D_linRegGDmulti.html#defStandardization">Definition 12</a> and the equation to scale a feature according to the standardization method.</em></p>
<p>Check your results by calling <code class="docutils literal notranslate"><span class="pre">df.describe()</span></code> on the updated dataframe.</p>
</section>
<section id="data-prep">
<h2>3. Data Prep<a class="headerlink" href="#data-prep" title="Permalink to this headline">#</a></h2>
<p>Let’s make the dataset ready for the classifier. As seen in class, the hypothesis function in the linear assumption has the dot product <span class="math notranslate nohighlight">\(\sum_{j=0}^n x^{(i)}_j \theta_j =  x^{(i)} \theta^{\; T}\)</span>, where by convention <span class="math notranslate nohighlight">\(x_0 = 1\)</span>. With 2 input features, there are two parameters to optimize for each feature and the intercept term <span class="math notranslate nohighlight">\(\theta_0\)</span>. To perform the dot product above, let’s add to the dataframe a column:</p>
<p><strong>3.1 Adding x0 column</strong><br />
Add a column <code class="docutils literal notranslate"><span class="pre">x0</span></code> to the dataframe <code class="docutils literal notranslate"><span class="pre">df</span></code> filled entirely with ones.</p>
<p><strong>3.2 Matrix X</strong><br />
Create a new dataframe <code class="docutils literal notranslate"><span class="pre">X</span></code> that contain the <code class="docutils literal notranslate"><span class="pre">x0</span></code> column and the columns of the two <strong>scaled</strong> input features.</p>
<p><strong>3.3 Labels to binary</strong><br />
The target column contains alphabetical labels. Create a dataframe <code class="docutils literal notranslate"><span class="pre">y</span></code> containing 1 if the sample is an electron shower and 0 if it is a hadron one.</p>
<p><em>Hint: you can first create an extra column full of 0, then apply a filter using the <code class="docutils literal notranslate"><span class="pre">.loc</span></code> property from DataFrame. It can be in the form:</em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span> <span class="n">CONDITION</span><span class="p">,</span> <span class="n">COLUMN_TO_UPDATE</span><span class="p">]</span> <span class="o">=</span> <span class="n">VALUE</span>
</pre></div>
</div>
<p>Read the <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html">pandas documentation on <code class="docutils literal notranslate"><span class="pre">.loc</span></code></a>.</p>
<p><strong>3.4 Vector y</strong><br />
Extract from the dataframe this <code class="docutils literal notranslate"><span class="pre">y</span></code> column with the binary labels in a separate dataframe <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</section>
<section id="dataframes-to-numpy">
<h2>4. DataFrames to Numpy<a class="headerlink" href="#dataframes-to-numpy" title="Permalink to this headline">#</a></h2>
<p>The inputs are almost ready, yet there are still some steps. As we saw in Lecture 3 in Part <a class="reference internal" href="../week1/class_algs_biasV.html#class-algs-perf"><span class="std std-ref">Performance Metrics</span></a>, we need to split the dataset in a training and a testing sets. We will use the very convenient <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> method from Sciki-Learn. Then, we convert the resulting dataframes to NumPy arrays. This Python library is the standard in data science. In this assignment, you will manipulate NumPy arrays and build the foundations you need to master the programming aspect of machine learning.</p>
<p>Copy this code into your notebook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train_df</span><span class="p">,</span> <span class="n">X_test_df</span><span class="p">,</span> <span class="n">y_train_df</span><span class="p">,</span> <span class="n">y_test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="p">;</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">X_test</span>  <span class="o">=</span> <span class="n">X_test_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>  <span class="p">;</span> <span class="n">y_test</span>  <span class="o">=</span> <span class="n">y_test_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>4.1 Shapes</strong><br />
Show the dimensions of the four NumPy arrays using the <code class="docutils literal notranslate"><span class="pre">.shape</span></code> property. Comment the numbers with respect to the notations defined in class. Does it make sense?</p>
<p><strong>4.2 Test size</strong><br />
Looking at the shapes, explain what <code class="docutils literal notranslate"><span class="pre">test_size</span></code> represents.</p>
</section>
<section id="useful-functions">
<h2>5. Useful Functions<a class="headerlink" href="#useful-functions" title="Permalink to this headline">#</a></h2>
<p>We saw a lot of functions in the lectures: hypothesis, logistic, cost, etc. We will code these functions as python functions to make the code more modular and easier to read.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In the following you will work with <strong>two dimensional</strong> NumPy arrays. Make sure the objects you declare in the code have the correct dimension (number of rows and number of columns).</p>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="seealso admonition">
<p class="admonition-title">Resource</p>
<p>A great tutorial: “How to Index, Slice and Reshape NumPy Arrays for Machine Learning” from Jason Brownlee on <a class="reference external" href="https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/">machinelearningmastery.com</a>.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is important that you test your functions to make sure they work and return coherent values. Create dummy arrays of just a couple of rows and the correct amount of columns, compute the expected values with a simple calculator to check. In your final notebook however, remove these checks for clarity and conciseness.</p>
</div>
</aside>
<p>To help you, look at the examples below.<br />
This creates a 2 x 3 matrix:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[1, 2, 3],</span>
<span class="go">       [4, 5, 6]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 3)</span>
</pre></div>
</div>
<p>This is a list:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="go">&lt;class &#39;list&#39;&gt;</span>
</pre></div>
</div>
<p>This makes a <strong>1D</strong> NumPy array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3,)</span>
</pre></div>
</div>
<p>This declares a <strong>2D</strong> NumPy array with one row (aka arow vector):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span>
<span class="go">array([[1, 2, 3]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(1, 3)</span>
</pre></div>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="seealso admonition">
<p class="admonition-title">Resource</p>
<p>Understand the <a class="reference external" href="https://numpy.org/doc/stable/user/quickstart.html#basic-operations">Basic Operations</a> with NumPy arrays.</p>
</div>
</aside>
<p><strong>5.1 Linear Sum</strong><br />
Write a function computing the linear sum of the features <span class="math notranslate nohighlight">\(X\)</span> with the <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> parameters for each input sample.</p>
<div class="math notranslate nohighlight">
\[z(\boldsymbol{x^{(i)}}) = \sum_{j=0}^n x^{(i)}_j \theta_j\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lin_sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">thetas</span><span class="p">):</span>

  <span class="c1"># Your code here </span>

</pre></div>
</div>
<p>What should be the dimensions of the returned object? Make sure your function returns a 2D array with the correct shape.</p>
<p><strong>5.2 Logistic Function</strong><br />
Write a function computing the logistic function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>

  <span class="c1"># Your code here </span>

</pre></div>
</div>
<p><strong>5.3 Hypothesis Function</strong><br />
Using the two functions above, write the hypothesis function <span class="math notranslate nohighlight">\(h_\theta(\boldsymbol{x^{(i)}})\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">h_class</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">thetas</span><span class="p">):</span>

  <span class="c1"># Your code here </span>
</pre></div>
</div>
<p><strong>5.4 Partial Derivatives of Cross-Entropy Cost Function</strong><br />
In the linear assumption where <span class="math notranslate nohighlight">\(z(\boldsymbol{x^{(i)}}) = \sum_{j=0}^n \theta_j x^{(i)}_j\)</span>, the partial derivatives of the cross-entropy cost function are:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial}{\partial \theta_j} J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) -  y^{(i)}\right) x_j^{(i)}\]</div>
<p>Write a function that takes <strong>three column vectors</strong> (m <span class="math notranslate nohighlight">\(\times\)</span> 1) and computes the partial derivatives <span class="math notranslate nohighlight">\(\frac{\partial}{\partial \theta_j} J(\theta)\)</span> for a given feature <span class="math notranslate nohighlight">\(j\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">derivatives_cross_entropy</span><span class="p">(</span><span class="n">y_preds</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">x_feature</span><span class="p">):</span>

  <span class="c1"># Your code here</span>

</pre></div>
</div>
<p>Hint: perform an array operation to store all the derivatives in a column vector. Then sum over the elements of that vector. At the end your function should return a scalar, i.e. one value.</p>
<p><strong>5.5 Cross-Entropy Cost Function</strong><br />
Write a function computing the total cost from the <strong>2D</strong> column vectors of predictions and observations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cross_entropy_cost</span><span class="p">(</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">):</span>

  <span class="c1"># Your code here</span>

</pre></div>
</div>
</section>
<section id="classifier">
<h2>6. Classifier<a class="headerlink" href="#classifier" title="Permalink to this headline">#</a></h2>
<p>The core of the action.</p>
<p>Luckily a skeleton is provided. You will have to replace the statments <code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">...</span> </code> by proper code. It will mostly consist of calling the functions you defined in the previous section.</p>
<p>Test your code frequently. To do so, you can assign dummy temporary values for the variables you do not use yet, so that python knows they are defined and your code can run.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="tip admonition">
<p class="admonition-title">Tip init</p>
<p>For initialization, use the <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html">NumPy <code class="docutils literal notranslate"><span class="pre">random</span></code> routine</a> to generate random numbers between 0 and 1.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The shape of the partial derivatives vector is provided (to help you). Now you need to call the function properly to get the values for <span class="math notranslate nohighlight">\(\frac{\partial}{\partial \theta_j} J(\theta)\)</span> !</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Tip partial derivatives</p>
<p>For extracting a given column in your <span class="math notranslate nohighlight">\(X\)</span> matrix, a good keyword to look for is ‘array slicing’. I stop giving you hints now.</p>
</div>
</aside>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hyperparameters</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="c1"># ...</span>
<span class="n">N</span> <span class="o">=</span>  <span class="c1"># ... epochs</span>

<span class="c1"># Number of features + 1 (number of columns in X)</span>
<span class="n">n</span> <span class="o">=</span> <span class="c1"># ...</span>

<span class="c1"># Initialization of theta *row vector*</span>
<span class="n">thetas</span> <span class="o">=</span> <span class="c1"># ...</span>

<span class="c1"># Storing cost values for train and test datasets</span>
<span class="n">costs_train</span> <span class="o">=</span> <span class="p">[]</span> 
<span class="n">costs_test</span>  <span class="o">=</span> <span class="p">[]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting gradient descent</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># -------------------</span>
<span class="c1">#   Start iterations</span>
<span class="c1"># -------------------</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>

  <span class="c1"># Get predictions (hypothesis function)</span>
  <span class="n">y_preds</span> <span class="o">=</span> <span class="c1"># ...</span>
  <span class="n">y_preds_test</span> <span class="o">=</span> <span class="c1"># ...</span>

  <span class="c1"># Calculate and store costs with train and test datasets</span>
  <span class="n">J_train</span> <span class="o">=</span> <span class="n">cross_entropy_cost</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">);</span> <span class="n">costs_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">J_train</span><span class="p">)</span>
  <span class="n">J_test</span>  <span class="o">=</span> <span class="n">cross_entropy_cost</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_preds_test</span><span class="p">);</span> <span class="n">costs_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">J_test</span><span class="p">)</span>

  <span class="c1"># Get partial derivatives d/dTheta_j </span>
  <span class="n">dJ_thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

  <span class="c1"># ...</span>

  <span class="c1"># Calculate new theta parameters:</span>
  <span class="n">thetas_new</span> <span class="o">=</span> <span class="c1"># ...</span>

  <span class="c1"># Update the parameters for the next iteration</span>
  <span class="c1"># ...</span>

  <span class="c1"># --------------------</span>
  <span class="c1">#  P R I N T O U T S</span>
  <span class="c1"># --------------------</span>
  <span class="c1"># Every 10 iterations and n &gt; 100 every 100 iterations</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">&lt;</span><span class="mi">100</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">i</span><span class="o">&gt;</span><span class="mi">100</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%d</span><span class="s1">]</span><span class="se">\t</span><span class="s1">t0 = </span><span class="si">%4.4f</span><span class="s1">  t1 = </span><span class="si">%4.4f</span><span class="s1">  t2 = </span><span class="si">%4.4f</span><span class="s1">  Cost = </span><span class="si">%4.4f</span><span class="s1">  dJ0 = </span><span class="si">%4.4f</span><span class="s1">  dJ1 = </span><span class="si">%4.4f</span><span class="s1">  dJ2 = </span><span class="si">%4.4f</span><span class="s1">&#39;</span> <span class="o">%</span>
         <span class="p">(</span> <span class="n">i</span><span class="p">,</span>   <span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>   <span class="n">J_train</span><span class="p">,</span>  <span class="n">dJ_thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>   <span class="n">dJ_thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>   <span class="n">dJ_thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">End of gradient descent after </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> iterations&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimized thetas:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Theta 0 = </span><span class="si">{</span><span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Theta 1 = </span><span class="si">{</span><span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Theta 2 = </span><span class="si">{</span><span class="n">thetas</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you struggle or cannot finish, summarize in your notebook your trials and investigations.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your classifier does not work, you can still answer the questions in Part 7.</p>
</div>
</aside>
</section>
<section id="plot-cost-versus-epochs">
<h2>7. Plot cost versus epochs<a class="headerlink" href="#plot-cost-versus-epochs" title="Permalink to this headline">#</a></h2>
<p>Use the following macro to plot the variation of the total cost vs the iteration number:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_cost_vs_iter</span><span class="p">(</span><span class="n">train_costs</span><span class="p">,</span> <span class="n">test_costs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Gradient Descent: Cost evolution&quot;</span><span class="p">):</span>
  
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="n">iters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">train_costs</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iters</span><span class="p">,</span> <span class="n">train_costs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training set&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iters</span><span class="p">,</span> <span class="n">test_costs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testing set&#39;</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of iterations&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Cost $J(\theta)$&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;horizontal&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_label_coords</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Call this macro:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_cost_vs_iter</span><span class="p">(</span><span class="n">costs_train</span><span class="p">,</span> <span class="n">costs_test</span><span class="p">)</span>
</pre></div>
</div>
<p>You should get something like this:</p>
<figure class="align-default" id="a01-cost-vs-n">
<a class="reference internal image-reference" href="../_images/a01_cost_vs_N.png"><img alt="../_images/a01_cost_vs_N.png" src="../_images/a01_cost_vs_N.png" style="width: 90%;" /></a>
</figure>
<p><strong>7.1: Describe the plot; what is the fundamental difference between the two series train and test?</strong></p>
<p><strong>7.2: What would it mean if there would be a bigger gap between the test and training values of the cost?</strong></p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="warning admonition">
<p class="admonition-title">Stuck? Ask me.</p>
<p>If you are stuck with the classifier, notify me and I will provide you with some <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> vector.</p>
</div>
</aside>
</section>
<section id="performance">
<h2>8. Performance<a class="headerlink" href="#performance" title="Permalink to this headline">#</a></h2>
<p>We will write our own functions to quantitatively assess the performance of the classifier.</p>
<p>Before counting the true and false predictions, we need… predictions! We already wrote a function <code class="docutils literal notranslate"><span class="pre">h_class</span></code> outputting a prediction as a <strong>continuous variable between 0 and 1</strong>, equivalent to a probabilitiy. The function below is calling <code class="docutils literal notranslate"><span class="pre">h_class</span></code> and then fills a <strong>python list</strong> of binary predictions, so either 0 or 1. For the boundary, recall in the lecture that the sigmoid is symmetric around y = 0.5, so we will work with this boundary for now. Copy this to your notebook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_predictions</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">boundary</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>

  <span class="n">bin_preds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">boundary</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">h_class</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">thetas</span><span class="p">))[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">]</span> 

  <span class="k">return</span> <span class="n">bin_preds</span>
</pre></div>
</div>
<p>Call the function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">make_predictions</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>We will work with lists from now on, so flatten the observed test values:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Turn y_test into 1D array:</span>
<span class="n">obs_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>8.1 Accuracy</strong><br />
Write a function computing the accuracy of the classifier:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">obs_values</span><span class="p">,</span> <span class="n">pred_values</span><span class="p">):</span>

  <span class="c1"># Your code here</span>

</pre></div>
</div>
<p>Call your function <strong>using the test set</strong> and print the result.</p>
<p><strong>8.2 Recall</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_recall</span><span class="p">(</span><span class="n">obs_values</span><span class="p">,</span> <span class="n">pred_values</span><span class="p">):</span>

  <span class="c1"># Your code here</span>

</pre></div>
</div>
<p>Call your function, still with the test set of course, and print the result.</p>
<p>BRAVO! You know now the math behind a binary classifier!</p>
</section>
<section id="x-bonus-decision-boundaries">
<h2>X. BONUS: Decision Boundaries<a class="headerlink" href="#x-bonus-decision-boundaries" title="Permalink to this headline">#</a></h2>
<p>This is for advanced programmers and/or your curiosity and/or if you have the time. Bonus points will be given even if you answer with math equations only and not necessarily the associated python code. Of course you if you succeed in getting the python, more bonus points for you!</p>
<p><strong>Goal</strong><br />
We want to draw on a scatter plot the lines corresponding to different decision boundaries.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Scroll down at the very end to see where we are heading to.</p>
</div>
<p><strong>X.0 Scatter plot</strong><br />
The first step is to split the signal and background into two different dataframes. Using the general dataframe <code class="docutils literal notranslate"><span class="pre">df</span></code> defined at the beginning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">all_sig</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;electron&#39;</span><span class="p">][[</span><span class="s1">&#39;shower_depth&#39;</span><span class="p">,</span> <span class="s1">&#39;shower_width&#39;</span><span class="p">]]</span>
<span class="n">all_bkg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span> <span class="o">==</span>  <span class="s1">&#39;hadron&#39;</span> <span class="p">][[</span><span class="s1">&#39;shower_depth&#39;</span><span class="p">,</span> <span class="s1">&#39;shower_width&#39;</span><span class="p">]]</span>
</pre></div>
</div>
<p>The plotting macro:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X1NAME</span> <span class="o">=</span> <span class="s1">&#39;shower_depth&#39;</span><span class="p">;</span> <span class="n">X1LABEL</span> <span class="o">=</span> <span class="s1">&#39;Shower depth [mm]&#39;</span>
<span class="n">X2NAME</span> <span class="o">=</span> <span class="s1">&#39;shower_width&#39;</span><span class="p">;</span> <span class="n">X2LABEL</span> <span class="o">=</span> <span class="s1">&#39;Shower width [mm]&#39;</span>
<span class="n">X1MIN</span>  <span class="o">=</span> <span class="mi">0</span> <span class="p">;</span> <span class="n">X1MAX</span> <span class="o">=</span> <span class="mi">200</span> 
<span class="n">X2MIN</span>  <span class="o">=</span> <span class="mi">0</span> <span class="p">;</span> <span class="n">X2MAX</span> <span class="o">=</span>  <span class="mi">60</span> 

<span class="c1"># Raw scatter plot</span>
<span class="k">def</span> <span class="nf">plot_scatter</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">bkg</span><span class="p">,</span> <span class="n">boundaries</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">x1name</span><span class="o">=</span><span class="n">X1NAME</span><span class="p">,</span> <span class="n">x1label</span><span class="o">=</span><span class="n">X1LABEL</span><span class="p">,</span> <span class="n">x1min</span><span class="o">=</span><span class="n">X1MIN</span><span class="p">,</span> <span class="n">x1max</span><span class="o">=</span><span class="n">X1MAX</span><span class="p">,</span>
                 <span class="n">x2name</span><span class="o">=</span><span class="n">X2NAME</span><span class="p">,</span> <span class="n">x2label</span><span class="o">=</span><span class="n">X2LABEL</span><span class="p">,</span> <span class="n">x2min</span><span class="o">=</span><span class="n">X2MIN</span><span class="p">,</span> <span class="n">x2max</span><span class="o">=</span><span class="n">X2MAX</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Scatter plot&quot;</span><span class="p">):</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

  <span class="c1"># ------------------</span>
  <span class="c1">#      A X E S  </span>
  <span class="c1"># ------------------</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="n">x1min</span><span class="p">,</span> <span class="n">x1max</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="n">x2min</span><span class="p">,</span> <span class="n">x2max</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">x1label</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">x2label</span><span class="p">)</span>

  <span class="c1"># ------------------</span>
  <span class="c1">#   S C A T T E R   </span>
  <span class="c1"># ------------------</span>
  <span class="n">scat_el</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sig</span><span class="p">[</span><span class="n">x1name</span><span class="p">],</span> <span class="n">sig</span><span class="p">[</span><span class="n">x2name</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;dodgerblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
  <span class="n">scat_had</span><span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">bkg</span><span class="p">[</span><span class="n">x1name</span><span class="p">],</span> <span class="n">bkg</span><span class="p">[</span><span class="n">x2name</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
  
  <span class="c1"># ----------------------</span>
  <span class="c1">#  B O U N D A R I E S</span>
  <span class="c1"># ----------------------</span>
  <span class="c1">#if boundaries: </span>
    <span class="c1"># ... stuff to do here</span>

  <span class="c1"># ------------------</span>
  <span class="c1">#   L E G E N D S </span>
  <span class="c1"># ------------------</span>
  <span class="c1"># Legend scatter</span>
  <span class="n">h</span> <span class="o">=</span> <span class="p">[</span><span class="n">scat_el</span><span class="p">,</span> <span class="n">scat_had</span><span class="p">]</span>
  <span class="n">legScatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">h</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;electron&#39;</span><span class="p">,</span> <span class="s1">&#39;hadron&#39;</span><span class="p">],</span>
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Shower type</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">title_fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">,</span> <span class="n">markerscale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                         <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.06</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;center left&quot;</span> <span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  
  <span class="c1"># Legend boundary</span>
  <span class="k">if</span> <span class="n">boundaries</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">legScatter</span><span class="p">)</span>
    <span class="n">legLines</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Decision boundaries&quot;</span><span class="p">,</span> 
                       <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.06</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;center left&quot;</span><span class="p">,</span> 
                       <span class="n">title_fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fontsize</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="p">;</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>To call it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">all_sig</span><span class="p">,</span> <span class="n">all_bkg</span><span class="p">,</span>
             <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Calorimeter Showers&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>X.1 Useful functions</strong><br />
Recall the logistic function:</p>
<div class="math notranslate nohighlight">
\[\hat{y} = \frac{1}{1 + e^{-z}}\]</div>
<p>Write a function <code class="docutils literal notranslate"><span class="pre">rev_sigmoid</span></code> that outputs the value <span class="math notranslate nohighlight">\(z = f(\hat{y})\)</span>.</p>
<p>Write a function <code class="docutils literal notranslate"><span class="pre">scale_inputs</span></code> that scales a list of raw input features, either <span class="math notranslate nohighlight">\(x_1\)</span> or <span class="math notranslate nohighlight">\(x_2\)</span>, according to the standardization procedure.</p>
<p>Write the function <code class="docutils literal notranslate"><span class="pre">unscale_inputs</span></code> that does the contrary.</p>
<p><strong>X.2 Equation</strong><br />
For a given threshold <span class="math notranslate nohighlight">\(\hat{y}\)</span>, write the equation of the line boundary: <span class="math notranslate nohighlight">\(x_2 = f(\boldsymbol{\theta}, x_1, \hat{y})\)</span>.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<div class="warning admonition">
<p class="admonition-title">Caution with notations</p>
<p>In our situation, the <span class="math notranslate nohighlight">\(x\)</span> axis corresponds to <span class="math notranslate nohighlight">\(x_1\)</span> and the <span class="math notranslate nohighlight">\(y\)</span> axis to <span class="math notranslate nohighlight">\(x_2\)</span>.</p>
</div>
</aside>
<p><strong>X.3 Boundary line coordinates</strong><br />
To draw a line on a plot in Matplotlib, one needs to provide the coordinates as a set of two data points: <code class="docutils literal notranslate"><span class="pre">[x_min,</span> <span class="pre">x_max],</span> <span class="pre">[y_left,</span> <span class="pre">y_right]</span></code>. The <code class="docutils literal notranslate"><span class="pre">y_left</span></code> correspond to the <span class="math notranslate nohighlight">\(x\)</span> coordinate <code class="docutils literal notranslate"><span class="pre">x_min</span></code>, and <code class="docutils literal notranslate"><span class="pre">y_right</span></code> to <code class="docutils literal notranslate"><span class="pre">x_max</span></code>.</p>
<p>Write a function that compute the coordinates <code class="docutils literal notranslate"><span class="pre">x2_left</span></code> and <code class="docutils literal notranslate"><span class="pre">x2_right</span></code> of a decision boundary line at a given threshold <span class="math notranslate nohighlight">\(\hat{y}\)</span>. (recall 0.5 is the standard one for logistic regression).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_boundary_line_x2</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">x1min</span><span class="o">=</span><span class="n">X1MIN</span><span class="p">,</span> <span class="n">x1max</span><span class="o">=</span><span class="n">X1MAX</span><span class="p">):</span>

  <span class="c1"># Your code here</span>


</pre></div>
</div>
<p>Warrior-level bonus: compute this for several thresholds, i.e. the function returns a list of line properties. Tip: it’s convenient to store the result in a dictionary. For instance you can have keys <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, <code class="docutils literal notranslate"><span class="pre">x2_left</span></code>, <code class="docutils literal notranslate"><span class="pre">x2_right</span></code>.</p>
<p><strong>X.4 Plotting the boundaries (advanced)</strong><br />
In the scatter plot code provided, uncomment the boundary section and draw the line(s) using the Matplotlib <code class="docutils literal notranslate"><span class="pre">plot</span></code> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>   <span class="c1">#... </span>
   <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x1min</span><span class="p">,</span> <span class="n">x1max</span><span class="p">],</span> <span class="p">[</span><span class="n">x2_left</span><span class="p">,</span> <span class="n">x2_right</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
   <span class="c1">#... </span>
</pre></div>
</div>
<p>In the very end, this is how it would render:</p>
<figure class="align-default" id="a01-scatter-with-boundaries">
<a class="reference internal image-reference" href="../_images/a01_scatter_with_boundaries.png"><img alt="../_images/a01_scatter_with_boundaries.png" src="../_images/a01_scatter_with_boundaries.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-text">Scatter plot of electron and hadron showers with decision boundary lines for various thresholds.<br />
<sub>Code will be shown while releasing solutions.</sub></span><a class="headerlink" href="#a01-scatter-with-boundaries" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The higher the threshold, the more the boundary line shifts downwards in the electron-dense area. Why is that the case?</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p> <br />
You are encouraged to work in groups, however submissions are individual.</p>
<p>If you have received help from your peers and/or have worked within a group, summarize in the header of your notebook the involved students, how they helped you and the contributions of each group member. This is to ensure fairness in the evaluation.</p>
<p>You can use the internet such as the official pages of relevant libraries, forum websites to debug, etc. However, using an AI such as ChatGPT would be considered cheating (and not good for you anyway to develop your programming skills).</p>
<p>The instructor and tutors are available throughout the week to answer your questions. Write an email with your well-articulated question(s). Put in CC your teammates if any.</p>
<p>Thank you and do not forget to have fun while coding!</p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./assignments"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Claire David<br/>
  
      &copy; Copyright 2022.<br/>
    <div class="extra_footer">
      <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>