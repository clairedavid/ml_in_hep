
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Cost Function for Classification &#8212; Machine Learning in Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Regularization" href="class_algs_reg.html" />
    <link rel="prev" title="What is the Sigmoid Function?" href="class_algs_sigmoid.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning in Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning in Particle Physics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About this course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/learningoutcomes.html">
   Learning outcomes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/instructor.html">
   Instructor &amp; Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/jupyter.html">
   JupyterHub for class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/evaluation.html">
   Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 1
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="trailer.html">
   1. Course Trailer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_hep.html">
     From detectors to publications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_mldef.html">
     What is Machine Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_pb.html">
     Which problems does ML solve?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="warmup_1D.html">
   2. Warm up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_linRegGD.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_linRegGDmulti.html">
     Multivariate linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_learningR.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_practice.html">
     Gradient Descent in practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="class_algs.html">
   3. Classification algorithms
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_logReg.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_reg.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_biasV.html">
     Performance Metrics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="BDTs.html">
   4. Decision Trees and Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_def.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_forest.html">
     Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_boosting.html">
     What is boosting?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="review_week1.html">
   5. Review Week 1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN1.html">
   6. Neural Networks Part I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_motivations.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_modelRep.html">
     Model Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_activationF.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_feedforward.html">
     Feedforward Propagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN2.html">
   7. Neural Networks Part II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_costF.html">
     Neural Network Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_init.html">
     Initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/DL.html">
   8. Towards Deep Learning Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_stochGD.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_adaptLR.html">
     Varying the Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_paramHyper.html">
     Hyperparameters in DL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_trainNN.html">
     Let’s train our NN!
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/CNN.html">
   9. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_resources.html">
     Learn CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_guest.html">
     Guest Lecture
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week2/review_week2.html">
   10. Review Week 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/unsupervised_learning.html">
   11. Unsupervised Learning Part I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_overview.html">
     Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_k-Means.html">
     k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_dimRed.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/unsupervised_learning2.html">
   12. Unsupervised Learning Part II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning2_autoEncoder.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning2_VAE_for_AD.html">
     Variational Autoencoder for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ML_BigData.html">
   13. Big Data &amp; ML Strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_7Vs.html">
     Big Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_strategies.html">
     Strategies in Machine Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ethics_outlook.html">
   14. Ethics in ML &amp; Outlook
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_outlook_1.html">
     Ethics in ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_outlook_2.html">
     Outlook
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week3/projects_exam.html">
   15. Project presentations &amp; Exam
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regression.html">
   1. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_forestry.html">
   2. ‘Forestree’ with LHC collisions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_class_game.html">
   3. Classification Contest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_anomaly_detection.html">
   4. Anomaly Detection
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fweek1/class_algs_costF.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/week1/class_algs_costF.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wavy-least-squares">
   Wavy least squares
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-new-cost-function">
   Building a new cost function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivatives-in-the-linear-case">
     Derivatives in the linear case
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-techniques">
     Alternative techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-than-two-categories-multiclassification">
   More than two categories: multiclassification
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Cost Function for Classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wavy-least-squares">
   Wavy least squares
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-new-cost-function">
   Building a new cost function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivatives-in-the-linear-case">
     Derivatives in the linear case
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-techniques">
     Alternative techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-than-two-categories-multiclassification">
   More than two categories: multiclassification
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="cost-function-for-classification">
<h1>Cost Function for Classification<a class="headerlink" href="#cost-function-for-classification" title="Permalink to this headline">#</a></h1>
<section id="wavy-least-squares">
<h2>Wavy least squares<a class="headerlink" href="#wavy-least-squares" title="Permalink to this headline">#</a></h2>
<p>If we plug our sigmoid hypothesis function <span class="math notranslate nohighlight">\(h_\theta(x)\)</span> into the cost function defined for linear regression (Equation <a class="reference internal" href="warmup_1D_linRegGD.html#equation-costfunctionlinreg">(3)</a> from Lecture 2), we will have a complex non-linear function that could be non-convex. The cost function could take this form:</p>
<figure class="align-default" id="poly3minima-example" style="width: 80%">
<div class="cell_output docutils container">
<img alt="../_images/class_algs_plots_10_0.png" src="../_images/class_algs_plots_10_0.png" />
</div>
</figure>
<p>Imagine running gradient descent starting from a randomly initialized <span class="math notranslate nohighlight">\(\theta_0\)</span> parameter around zero (or worse, lower than -2). It will fall into a local minima. Our cost function will not be at the global minimum! It is crucial to work with a cost function accepting one unique minimum.</p>
</section>
<section id="building-a-new-cost-function">
<h2>Building a new cost function<a class="headerlink" href="#building-a-new-cost-function" title="Permalink to this headline">#</a></h2>
<p>As we saw in the previous section, the sigmoid fits the 1D data distribution very well. Our cost function will use the hypothesis <span class="math notranslate nohighlight">\(h_\theta(x)\)</span> function as input. Recall that the hypothesis <span class="math notranslate nohighlight">\(h_\theta(x)\)</span> is bounded between 0 and 1. What we need is a cost function producing high values if we mis-classify events and values close to zero if we correctly label the data. Let’s examine what we want for the two cases:</p>
<p><strong>Case of a signal event:</strong><br />
A data point labelled signal verifies by our convention <span class="math notranslate nohighlight">\(y=1\)</span>. If our hypothesis <span class="math notranslate nohighlight">\(h_\theta(x)\)</span> is also 1, then we have a good prediction. The cost value should be zero. If however our signal sample has a wrong prediction <span class="math notranslate nohighlight">\(h_\theta(x) = 0\)</span>, then the cost function should take large values to penalize this bad prediction. We need thus a strictly decreasing function, starting with high values and cancelling at the coordinate (1, 0).</p>
<p><strong>Case of a background event:</strong><br />
The sigmoid can be interpreted as a probability for a sample being signal or not (but note it is not a probability distribution function). As we have only two outcomes, the probability for a data point to be non signal will be in the form of <span class="math notranslate nohighlight">\(1 - h_\theta(x)\)</span>. We want to find a function with this time a zero cost if the prediction <span class="math notranslate nohighlight">\(h_\theta(x) = 0\)</span> and a high cost for an erroneous prediction <span class="math notranslate nohighlight">\(h_\theta(x) = 1\)</span>.</p>
<p>Now let’s have a look at these two functions:</p>
<figure class="align-default" id="log-h-x" style="width: 100%">
<div class="cell_output docutils container">
<img alt="../_images/class_algs_plots_12_1.png" src="../_images/class_algs_plots_12_1.png" />
</div>
</figure>
<p>For each case, the cost function has only one minimum and harshly penalizes wrong prediction by blowing up at infinity.<br />
How to combine these two into one cost function for logistic regression?<br />
Like this:</p>
<div class="proof definition admonition" id="costFLogRegDef">
<p class="admonition-title"><span class="caption-number">Definition 19 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>cost function for logistic regression</strong> is a defined as:</p>
<div class="math notranslate nohighlight" id="equation-costfunctionlogreg">
<span class="eqno">(13)<a class="headerlink" href="#equation-costfunctionlogreg" title="Permalink to this equation">#</a></span>\[J(\theta) = - \frac{1}{m} \sum^m_{i=1} \left[ \;\; {\color{RoyalBlue}y^{(i)} \log( h_\theta(x^{(i)} )) }\;\;+\;\; {\color{OliveGreen}(1- y^{(i)}) \log( 1 - h_\theta(x^{(i)} ))} \;\;\right]\]</div>
<p>This function is also called <strong>cross-entropy loss function</strong> and is the standard cost function for binary classifiers.</p>
</section>
</div><p>Note the negative sign factorized at the beginning of the equation. Multiplying by <span class="math notranslate nohighlight">\({\color{RoyalBlue}y^{(i)}}\)</span> and <span class="math notranslate nohighlight">\({\color{OliveGreen}(1 - y^{(i)})}\)</span> the first and second term of the sum respectively acts as a “switch” between the cases <span class="math notranslate nohighlight">\({\color{RoyalBlue}y=1}\)</span> and <span class="math notranslate nohighlight">\({\color{OliveGreen}y=0}\)</span>. If <span class="math notranslate nohighlight">\({\color{RoyalBlue}y=1}\)</span>, the first term cancels out and the cost takes the value of the second. If <span class="math notranslate nohighlight">\({\color{OliveGreen}y=0}\)</span>, the second term vanishes. The two cases are combined into one mathematical expression.</p>
</section>
<section id="gradient-descent">
<h2>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h2>
<p>The gradient descent for classification follows the same procedure as described in Algorithm <a class="reference internal" href="warmup_1D_linRegGDmulti.html#GD_algo_multi">Algorithm 2</a> in Section <a class="reference internal" href="warmup_1D_linRegGDmulti.html#warmup-linregmulti-graddesc"><span class="std std-ref">Gradient Descent in Multilinear Regression</span></a> with the definition of the cost function from Equation <a class="reference internal" href="#equation-costfunctionlogreg">(13)</a> above.</p>
<section id="derivatives-in-the-linear-case">
<h3>Derivatives in the linear case<a class="headerlink" href="#derivatives-in-the-linear-case" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recall that <span class="math notranslate nohighlight">\(h_\theta (x^{(i)}) =  f( x^{(i)}\theta^{T}) = \frac{1}{1 + e^{-  x^{(i)} \theta^{T}}}\)</span></p>
</aside>
<p>Consider the linear assumption <span class="math notranslate nohighlight">\(x^{(i)}\theta^{\; T}  = \theta_0 + \theta_1 x_1 +  \cdots  + \theta_n x_n\)</span> as input to the sigmoid function <span class="math notranslate nohighlight">\(f\)</span>.
The cost function derivatives will take the form:</p>
<div class="math notranslate nohighlight" id="equation-costfderivlin">
<span class="eqno">(14)<a class="headerlink" href="#equation-costfderivlin" title="Permalink to this equation">#</a></span>\[\frac{\partial}{\partial \theta_j} J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) -  y^{(i)}\right) x_j^{(i)}\]</div>
<p>This takes the same form as the derivatives for linear regression (Equation <a class="reference internal" href="warmup_1D_linRegGDmulti.html#equation-partialdevlinreg">(10)</a> in Section <a class="reference internal" href="warmup_1D_linRegGDmulti.html#warmup-linregmulti-graddesc"><span class="std std-ref">Gradient Descent in Multilinear Regression</span></a>).</p>
<div class="seealso admonition">
<p class="admonition-title">Exercise</p>
<p>To convince yourself, you can derive Equation <a class="reference internal" href="#equation-costfderivlin">(14)</a> starting from Equation <a class="reference internal" href="#equation-costfunctionlogreg">(13)</a>.</p>
<p>Hints and help available on demand after class.</p>
</div>
</section>
<section id="alternative-techniques">
<h3>Alternative techniques<a class="headerlink" href="#alternative-techniques" title="Permalink to this headline">#</a></h3>
<p>Beside logistic regression, other algorithms are designed for binary classification.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Perceptron">Perceptron</a>, which is a single layer neural network with, in its original form, a step function instead of a sigmoid function. We will cover neural networks in Lectures 6 and 7.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machines (SVMs)</a> are robust and widely used in classification problems. We will not cover them here but below are some links for further reading.</p>
<div class="seealso admonition">
<p class="admonition-title">Learn more</p>
<ul class="simple">
<li><p>R. Berwick, An Idiot’s guide to Support vector machines (SVMs) on <a class="reference external" href="https://web.mit.edu/6.034/wwwbob/svm.pdf">web.mit.edu</a></p></li>
<li><p>Support Vector Machines: A Simple Explanation, on <a class="reference external" href="https://www.kdnuggets.com/2016/07/support-vector-machines-simple-explanation.html">KDNuggets</a></p></li>
<li><p>Support Vector Machines: Main Ideas” by Josh Starmer, <a class="reference external" href="https://www.youtube.com/watch?v=efR1C6CvhmE">Video, Part 1/3, StatQuest channel on YouTube</a></p></li>
</ul>
</div>
<p>Numerous methods have been developed to find optimized <span class="math notranslate nohighlight">\(\theta\)</span> parameters in faster ways than the gradient descent. These optimizers are beyond the scope of this course and usually available as libraries within python (or other languages). Below is a list of the most popular ones:</p>
<div class="seealso admonition">
<p class="admonition-title">Learn more</p>
<ul class="simple">
<li><p>The BFGS algorithm: <a class="reference external" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">Wikipedia article</a></p></li>
<li><p>The Limited-memory BFGS, L-BFGS: <a class="reference external" href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">Wikipedia article</a></p></li>
<li><p>Conjugate gradient method: <a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Wikipedia article</a></p></li>
<li><p><a class="reference external" href="https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf">An Introduction to the Conjugate Gradient Method Without the Agonizing Pain, Jonathan Richard Shewchuk (1994)</a></p></li>
</ul>
</div>
</section>
</section>
<section id="more-than-two-categories-multiclassification">
<h2>More than two categories: multiclassification<a class="headerlink" href="#more-than-two-categories-multiclassification" title="Permalink to this headline">#</a></h2>
<p>We treated the binary classification problem. How to adapt to a situation with more than two classes?</p>
<p>A multi-class classification problem can be split into multiple binary classification datasets and be trained as a binary classification model each.
Such approach is a heuristic method, that is to say not optimal nor direct. But it eventually does the job.
There are two main approaches of such methods for multiclassification.</p>
<div class="proof definition admonition" id="multiclass1to1def">
<p class="admonition-title"><span class="caption-number">Definition 20 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>One-to-One approach</strong> consists of applying a binary classification for each pair of classes, ignoring the other classes.</p>
<p>With a dataset made of <span class="math notranslate nohighlight">\(N^\text{class}\)</span> classes, the number of models to train, <span class="math notranslate nohighlight">\(N^\text{model}\)</span> is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-71ab13fa-80db-4632-9bd3-f979c32be1e4">
<span class="eqno">(15)<a class="headerlink" href="#equation-71ab13fa-80db-4632-9bd3-f979c32be1e4" title="Permalink to this equation">#</a></span>\[\begin{equation}
N^\text{model} = \frac{N^\text{class}(N^\text{class}-1)}{2}
\end{equation}\]</div>
<p>Each model predicts one class label. The final decision is the class label receiving the most votes, i.e. being predicted most of the time.</p>
</section>
</div><p><strong>Pro</strong><br />
The sample size is more balanced between the two chosen classes than if datasets were split with one class against all others.</p>
<p><strong>Con</strong><br />
The pairing makes the number of models to train large and thus computer intensive.</p>
<div class="proof definition admonition" id="multiclass1toalldef">
<p class="admonition-title"><span class="caption-number">Definition 21 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>One-to-All or One-to-Rest approach</strong> consists of training each class against the collection of all other classes.</p>
<p>With a dataset made of <span class="math notranslate nohighlight">\(N^\text{class}\)</span> classes, the number of pairs to train is</p>
<div class="amsmath math notranslate nohighlight" id="equation-66520ad7-0fac-474a-a6f1-23cbe7fda017">
<span class="eqno">(16)<a class="headerlink" href="#equation-66520ad7-0fac-474a-a6f1-23cbe7fda017" title="Permalink to this equation">#</a></span>\[\begin{equation}
 N^\text{model} = N^\text{class}
\end{equation}\]</div>
<p>The final prediction is given by the highest value of the hypothesis function <span class="math notranslate nohighlight">\(h^{k}_\theta(x)\)</span>, <span class="math notranslate nohighlight">\(k \in [1, N^\text{model}]\)</span> among the <span class="math notranslate nohighlight">\(N^\text{model}\)</span> binary classifiers.</p>
</section>
</div><p><strong>Pro</strong><br />
Less binary classifiers to train.</p>
<p><strong>Con</strong><br />
The number of data points from the class to look for will be very small if the ‘background’ class is the merging of all other data points from the other classes.</p>
<p>Illustrations. Let’s consider three classes, labelled with their colours and distributed in two dimensions (two input features) like this:</p>
<figure class="align-default" id="lec03-3-multiclass-1">
<a class="reference internal image-reference" href="../_images/lec03_3_multiclass-1.webp"><img alt="../_images/lec03_3_multiclass-1.webp" src="../_images/lec03_3_multiclass-1.webp" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">. 2D distribution of three different classes.<br />
<sub>Image: <a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/05/multiclass-classification-using-svm/">analyticsvidhya.com</a></sub></span><a class="headerlink" href="#lec03-3-multiclass-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The One-to-One method would create those hyperplanes (with two input features, D = 2 we will have a 1D line as separation):</p>
<figure class="align-default" id="lec03-3-multiclass-2">
<a class="reference internal image-reference" href="../_images/lec03_3_multiclass-2.webp"><img alt="../_images/lec03_3_multiclass-2.webp" src="../_images/lec03_3_multiclass-2.webp" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">. One-to-One approach splits paired datasets, ignoring the points of the other classes.<br />
<sub>Image: <a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/05/multiclass-classification-using-svm/">analyticsvidhya.com</a></sub></span><a class="headerlink" href="#lec03-3-multiclass-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="lec03-3-multiclass-3">
<a class="reference internal image-reference" href="../_images/lec03_3_multiclass-3.webp"><img alt="../_images/lec03_3_multiclass-3.webp" src="../_images/lec03_3_multiclass-3.webp" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 22 </span><span class="caption-text">. One-to-All approach focuses on one class to discriminate from all other points<br />
(i.e. all other classes are merged into a single ‘background’ class).<br />
<sub>Image: <a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/05/multiclass-classification-using-svm/">analyticsvidhya.com</a></sub></span><a class="headerlink" href="#lec03-3-multiclass-3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Some further reading if you are curious:</p>
<div class="seealso admonition">
<p class="admonition-title">Learn more</p>
<ul class="simple">
<li><p><a class="reference external" href="https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/">One-vs-Rest and One-vs-One for Multi-Class Classification, machinelearningmastery.com</a></p></li>
<li><p><a class="reference external" href="https://www.analyticsvidhya.com/blog/2021/05/multiclass-classification-using-svm/">Multiclass Classification Using SVM, analyticsvidhya.com</a></p></li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./week1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="class_algs_sigmoid.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">What is the Sigmoid Function?</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="class_algs_reg.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Regularization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Claire David<br/>
  
      &copy; Copyright 2022.<br/>
    <div class="extra_footer">
      <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>