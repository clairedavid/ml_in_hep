
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Regularization &#8212; Machine Learning in Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bias, Variance: how to cope" href="class_algs_biasV.html" />
    <link rel="prev" title="Cost Function for Classification" href="class_algs_costF.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning in Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning in Particle Physics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/learningoutcomes.html">
   Learning outcomes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/jupyter.html">
   JupyterHub for class
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 1
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="trailer.html">
   1. Course Trailer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_hep.html">
     From detectors to publications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_mldef.html">
     What is Machine Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="trailer_pb.html">
     Which problems does ML solve?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="warmup_1D.html">
   2. Warm up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_linRegGD.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_linRegGDmulti.html">
     Multivariate linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_learningR.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="warmup_1D_practice.html">
     Gradient Descent in practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="class_algs.html">
   3. Classification algorithms
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_logReg.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_costF.html">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="class_algs_biasV.html">
     Bias, Variance: how to cope
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="BDTs.html">
   4. Decision Trees and Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_def.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_forest.html">
     Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="BDTs_boosting.html">
     What is boosting?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="review_week1.html">
   5. Review Week 1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN1.html">
   6. Neural Networks Part I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_motivations.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_modelRep.html">
     Model Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_activationF.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN1_feedforward.html">
     Feedforward Propagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/NN2.html">
   7. Neural Networks Part II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_costF.html">
     Neural Network Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_init.html">
     Initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/NN2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/DL.html">
   8. Towards Deep Learning Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_stochGD.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_trainNN.html">
     Let’s train our NN!
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_paramHyper.html">
     Hyperparameters in DL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/DL_adaptLR.html">
     Adaptative Learning Rates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week2/CNN.html">
   9. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_architecture.html">
     Architecture of a CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_hyperparameters.html">
     Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_regMethods.html">
     Regularization Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week2/CNN_neutrinoReco.html">
     Application in Neutrino Physics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week2/review_week2.html">
   10. Review Week 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/unsupervised_learning.html">
   11. Unsupervised learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_motiv.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_relevance.html">
     Relevance and examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_k-Means.html">
     k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_dimRed.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/PCA_AD.html">
   12. PCA and Anomaly Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_PCA.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_autoEncoder.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_VAE_for_AD.html">
     Variational Autoencoder for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ML_BigData.html">
   13. ML in Big Data &amp; Strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_7Vs.html">
     The 7V’s of Big Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_preproc.html">
     Data Preprocessing Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_chooseAlgo.html">
     How to Choose an Optimization Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ethics_exam.html">
   14. Ethics in ML &amp; Exam
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_exam_1.html">
     The Ethics in ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_exam_2.html">
     Course Exam
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/projects_outlook.html">
   15. Project presentations &amp; Outlook
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/projects_outlook_pres.html">
     Project Presentations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/projects_outlook_today.html">
     Open Questions in ML today
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regression.html">
   1. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_forestry.html">
   2. Event Classification with Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_nn_by_hand.html">
   3. Neural Network By Hand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_class_game.html">
   4. Classification Contest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t05_anomaly_detection.html">
   5. Neural Networks by hand
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fweek1/class_algs_reg.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/week1/class_algs_reg.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#underfitting-overfitting">
   Underfitting, overfitting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization-types">
   Regularization types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ridge-regression">
     Ridge Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-regularization">
     Lasso Regularization
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Regularization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#underfitting-overfitting">
   Underfitting, overfitting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularization-types">
   Regularization types
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ridge-regression">
     Ridge Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-regularization">
     Lasso Regularization
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="regularization">
<span id="class-algs-reg"></span><h1>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">#</a></h1>
<p>A converging gradient descent is not the end of the story. The learning algorithm can fit the data too specifically to the training samples and would fail once given additional data, compromising the accuracy of predictions: this is overfitting. To prevent this, a regularizing term is added in the cost function to constrain the parameters.</p>
<section id="underfitting-overfitting">
<h2>Underfitting, overfitting<a class="headerlink" href="#underfitting-overfitting" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="underfittingdef">
<p class="admonition-title"><span class="caption-number">Definition 22 </span></p>
<section class="definition-content" id="proof-content">
<p><strong>Underfitting</strong> is a situation that occurs when a fitting procedure or machine learning algorithm is not capturing the general trend of the dataset.</p>
</section>
</div><p>Another way to put it: an underfit algorithm lacks complexity.</p>
<p>The antonym of underfitting is overfitting.</p>
<div class="proof definition admonition" id="overfittingdef">
<p class="admonition-title"><span class="caption-number">Definition 23 </span></p>
<section class="definition-content" id="proof-content">
<p><strong>Overfitting</strong> is a situation that occurs when a fitting procedure or machine learning algorithm matches too precisely a particular collection of a dataset.</p>
</section>
</div><p>Overfitting is synonym of overtuned, overtweaked. In other words: the model learns the detail and noise in the training dataset to the extent that it negatively impacts the performance of the model on a new dataset. This means that the noise or random fluctuations in the training dataset is picked up and learned as concepts by the model.
In machine learning, we look for trends and compromises: a good algorithm may not be perfectly classifying a given data set; it needs to accommodate and ignore rare outliers so that future predictions, on average, will be accurate (we will see how to diagnose learners in the next section).</p>
<p>The problem with overfitting is the future consequences once the machine learning algorithm receives additional data: it may lack flexibility.</p>
<div class="proof definition admonition" id="flexibilitydef">
<p class="admonition-title"><span class="caption-number">Definition 24 </span></p>
<section class="definition-content" id="proof-content">
<p>The <strong>flexibility</strong> of a model determines its ability to generalize to different characteristic of the data.</p>
</section>
</div><p>In some definitions (it seems there is no standard definition of flexibility), the literature quotes “to increase the degrees of freedom available to the model to fit to the training data.” What are degrees of freedom in this context? Think of data points distributed along a parabola. A linear model will be underfitting the data as it is too simple to catch the parabolic trend with only two degrees of freedom (remember there are two parameters to optimize). A quadratic equation, however, will manage well with three degrees of freedom. A model with more degrees of freedom has margin to adapt well to different situations. This is the idea behind flexibility.</p>
<figure class="align-default" id="lec03-4-underoverfit-png">
<a class="reference internal image-reference" href="../_images/lec03_4_underoverfit.png"><img alt="../_images/lec03_4_underoverfit.png" src="../_images/lec03_4_underoverfit.png" style="width: 1200px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 23 </span><span class="caption-text">. Example of several regression models.<br />
The linear one on the left (Degree 1) is underfitting the data. The model on the right (Degree 15) is overfitting the data as its high polynomial produces a curve over-specific to the given data set. The middle model (Degree 4) is a good compromise.<br />
<sub>Source: <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html">scikit-learn.org (with associated python code)</a></sub></span><a class="headerlink" href="#lec03-4-underoverfit-png" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>How to avoid overfitting?</p>
</section>
<section id="regularization-types">
<h2>Regularization types<a class="headerlink" href="#regularization-types" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="regularizationdef">
<p class="admonition-title"><span class="caption-number">Definition 25 </span></p>
<section class="definition-content" id="proof-content">
<p><strong>Regularization</strong> in machine learning is a processus consisting of adding constraints on a model’s parameters.</p>
</section>
</div><p>The two main types of regularization techniques are the Ridge Regularization (also known as <a class="reference external" href="https://en.wikipedia.org/wiki/Tikhonov_regularization">Tikhonov regularization</a>, albeit the latter is more general) and the Lasso Regularization.</p>
<section id="ridge-regression">
<h3>Ridge Regression<a class="headerlink" href="#ridge-regression" title="Permalink to this headline">#</a></h3>
<p>The Ridge regression is a linear regression with an additional regularization term added to the cost function:</p>
<div class="math notranslate nohighlight" id="equation-ridgeeq">
<span class="eqno">(17)<a class="headerlink" href="#equation-ridgeeq" title="Permalink to this equation">#</a></span>\[ J(\theta) = \frac{1}{2m} \left[ \sum_{i=1}^{m} \left( h_\theta(x^{(i)}) -  y^{(i)}\right)^2 + {\color{Maroon}\lambda \sum_{j=1}^n \theta_j^2} \right]\]</div>
<p>The hyperparameter <span class="math notranslate nohighlight">\(\lambda\)</span> controls the degree of regularization. If <span class="math notranslate nohighlight">\(\lambda = 0\)</span>, the regularization term vanishes and we have a non-regularized linear regression. You can see the penalty imposed by the term <span class="math notranslate nohighlight">\(\lambda\)</span> will force the parameters <span class="math notranslate nohighlight">\(\theta\)</span> to be as small as possible; this helps avoiding overfitting. If <span class="math notranslate nohighlight">\(\lambda\)</span> gets very large, the parameters can be so shrinked that the model becomes over-simplified to a straight line and thus underfit the data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> is used in some derivations of the regularization. This makes it easier to calculate the gradient, however it is only a constant value that can be compensated by the choice of the parameter <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The offset parameter <span class="math notranslate nohighlight">\(\theta_0\)</span> is not entering in the regularization sum.</p>
</div>
<p>In the litterature, the parameters are denoted with <span class="math notranslate nohighlight">\(b\)</span> for the offset (bias) and a vector of weight <span class="math notranslate nohighlight">\(\vec{w}\)</span> for the other parameters <span class="math notranslate nohighlight">\(\theta_1, \theta_2, \cdots \theta_n\)</span>. Thus the regularization term is written:</p>
<div class="math notranslate nohighlight" id="equation-regl2weq">
<span class="eqno">(18)<a class="headerlink" href="#equation-regl2weq" title="Permalink to this equation">#</a></span>\[\lambda \left(\left\| \vec{w} \right\|_2\right)^2\]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The <span class="math notranslate nohighlight">\(\ell_2\)</span> norm is the Euclidian norm <span class="math notranslate nohighlight">\(\left\| x \right\|_2 = \sqrt{x_0^2 + x_1^2 + \cdots + x_n^2}\)</span>.</p>
</aside>
<p>with <span class="math notranslate nohighlight">\(\left\| \vec{w} \right\|_2\)</span> the <span class="math notranslate nohighlight">\(\ell_2\)</span> norm of the weight vector.</p>
<p>For logistic regression, the regularized cost function becomes:</p>
<div class="math notranslate nohighlight" id="equation-ridgelogeq">
<span class="eqno">(19)<a class="headerlink" href="#equation-ridgelogeq" title="Permalink to this equation">#</a></span>\[ J(\theta) = - \frac{1}{m} \sum^m_{i=1} \left[ \;\; y^{(i)} \log( h_\theta(x^{(i)} )) \;+\; (1- y^{(i)}) \log( 1 - h_\theta(x^{(i)} )) \;\;\right] + {\color{Maroon}\frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2}\]</div>
</section>
<section id="lasso-regularization">
<span id="class-algs-reg-lasso"></span><h3>Lasso Regularization<a class="headerlink" href="#lasso-regularization" title="Permalink to this headline">#</a></h3>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The <span class="math notranslate nohighlight">\(\ell_1\)</span> norm is the sum of the magnitudes of the vectors. It is also called Manhattan or <a class="reference external" href="https://en.wikipedia.org/wiki/Taxicab_geometry">Taxicab norm</a>.</p>
</aside>
<p>Lasso stands for least absolute shrinkage and selection operator. Behind the long acronym is a regularization of the linear regression using the <span class="math notranslate nohighlight">\(\ell_1\)</span> norm. We denote Cost(<span class="math notranslate nohighlight">\(\theta\)</span>) the cost function, i.e. either the Mean Squared Error for linear regression or the cross-entropy loss function <a class="reference internal" href="class_algs_costF.html#equation-costfunctionlogreg">(13)</a> for logistic regression. The lasso regression cost function is</p>
<div class="math notranslate nohighlight" id="equation-lassocostf">
<span class="eqno">(20)<a class="headerlink" href="#equation-lassocostf" title="Permalink to this equation">#</a></span>\[J(\theta) = \text{Cost}{\theta}  + {\color{Maroon}\frac{\lambda}{2m} \sum_{j=1}^n \theta_j}\]</div>
<p>The regularizing term uses the <span class="math notranslate nohighlight">\(\ell_1\)</span> norm of the weight vector: <span class="math notranslate nohighlight">\(\left\| \vec{w} \right\|_1\)</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>As regularization influences the parameters, it is important to first perform feature scaling before applying the regularization.</p>
</div>
<p><strong>Which regularization method to use?</strong></p>
<p>Each one has its pros and cons. As <span class="math notranslate nohighlight">\(\ell_1\)</span> (lasso) is a sum of absolute values, it is not differentiable and thus more computationally expensive. Yet <span class="math notranslate nohighlight">\(\ell_1\)</span> better deals with outliers (extreme values in the data) by not squaring their values. It is said to be more robust, i.e. more resilient to outliers in a dataset.</p>
<p>The <span class="math notranslate nohighlight">\(\ell_1\)</span> regularization, by shriking some parameters to zero (making them vanish and no more influencial), has <em>feature selection</em> built in by design. If this can be advantageous in some cases, it can mishandle highly correlated features by arbitrarily selecting one over the others.</p>
<p>Additional reading are provided below to deepen your understanding in the different regularization methods. Take home message: both methods combat overfitting.</p>
<div class="seealso admonition">
<p class="admonition-title">Learn more</p>
<ul class="simple">
<li><p>A comparison of the pros and cons of Ridge (<span class="math notranslate nohighlight">\(\ell_2\)</span> norm) and lasso (<span class="math notranslate nohighlight">\(\ell_1\)</span> norm) regularization: <a class="reference external" href="https://www.kaggle.com/code/residentmario/l1-norms-versus-l2-norms/notebook">“L1 Norms versus L2 Norms”, Kaggle</a></p></li>
<li><p><a class="reference external" href="https://neptune.ai/blog/fighting-overfitting-with-l1-or-l2-regularization">Figting overfitting with <span class="math notranslate nohighlight">\(\ell_1\)</span> or <span class="math notranslate nohighlight">\(\ell_2\)</span> regularization, neptune.ai</a></p></li>
</ul>
</div>
<p>How can we inspect our machine learning algorithm to assess, even quantify the presence of under or overfitting? This is what we cover in the next section.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./week1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="class_algs_costF.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Cost Function for Classification</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="class_algs_biasV.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bias, Variance: how to cope</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Claire David<br/>
  
      &copy; Copyright 2022.<br/>
    <div class="extra_footer">
      <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>