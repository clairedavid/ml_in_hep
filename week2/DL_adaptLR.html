
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Varying the Learning Rate &#8212; Machine Learning in Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hyperparameters in DL" href="DL_paramHyper.html" />
    <link rel="prev" title="Stochastic Gradient Descent" href="DL_stochGD.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning in Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Machine Learning in Particle Physics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/learningoutcomes.html">
   Learning outcomes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/jupyter.html">
   JupyterHub for class
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/trailer.html">
   1. Course Trailer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_hep.html">
     From detectors to publications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_mldef.html">
     What is Machine Learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/trailer_pb.html">
     Which problems does ML solve?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/warmup_1D.html">
   2. Warm up: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_linRegGD.html">
     Gradient Descent in 1D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_linRegGDmulti.html">
     Multivariate linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_learningR.html">
     Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/warmup_1D_practice.html">
     Gradient Descent in practice
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/class_algs.html">
   3. Classification algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_logReg.html">
     Logistic Regression: introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_sigmoid.html">
     What is the Sigmoid Function?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_costF.html">
     Cost Function for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_reg.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/class_algs_biasV.html">
     Bias, Variance: how to cope
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week1/BDTs.html">
   4. Decision Trees and Boosting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_def.html">
     What are Decision Trees?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_forest.html">
     Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week1/BDTs_boosting.html">
     What is boosting?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week1/review_week1.html">
   5. Review Week 1
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 2
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="NN1.html">
   6. Neural Networks Part I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NN1_motivations.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN1_modelRep.html">
     Model Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN1_activationF.html">
     Activation Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN1_feedforward.html">
     Feedforward Propagation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="NN2.html">
   7. Neural Networks Part II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NN2_costF.html">
     Neural Network Loss Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN2_init.html">
     Initialization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="NN2_backprop.html">
     Backpropagation Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="DL.html">
   8. Towards Deep Learning Models
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="DL_stochGD.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Varying the Learning Rate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DL_paramHyper.html">
     Hyperparameters in DL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DL_trainNN.html">
     Let’s train our NN!
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="CNN.html">
   9. Convolutional Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="CNN_architecture.html">
     Architecture of a CNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="CNN_hyperparameters.html">
     Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="CNN_regMethods.html">
     Regularization Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="CNN_neutrinoReco.html">
     Application in Neutrino Physics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="review_week2.html">
   10. Review Week 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Week 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/unsupervised_learning.html">
   11. Unsupervised learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_motiv.html">
     Motivations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_relevance.html">
     Relevance and examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_k-Means.html">
     k-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/unsupervised_learning_dimRed.html">
     Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/PCA_AD.html">
   12. PCA and Anomaly Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_PCA.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_autoEncoder.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/PCA_AD_VAE_for_AD.html">
     Variational Autoencoder for Anomaly Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ML_BigData.html">
   13. ML in Big Data &amp; Strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_7Vs.html">
     The 7V’s of Big Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_preproc.html">
     Data Preprocessing Pipelines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ML_BigData_chooseAlgo.html">
     How to Choose an Optimization Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/ethics_exam.html">
   14. Ethics in ML &amp; Exam
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_exam_1.html">
     The Ethics in ML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/ethics_exam_2.html">
     Course Exam
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../week3/projects_outlook.html">
   15. Project presentations &amp; Outlook
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/projects_outlook_pres.html">
     Project Presentations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week3/projects_outlook_today.html">
     Open Questions in ML today
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t01_linear_regression.html">
   1. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t02_forestry.html">
   2. Event Classification with Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t03_nn_by_hand.html">
   3. Neural Network By Hand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t04_class_game.html">
   4. Classification Contest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorials/t05_anomaly_detection.html">
   5. Neural Networks by hand
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fweek2/DL_adaptLR.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/week2/DL_adaptLR.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivations">
   Motivations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-rate-schedulers">
   Learning Rate Schedulers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#power-scheduling">
     Power Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#time-based-decay-scheduling">
     Time-Based Decay Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-decay-scheduling">
     Exponential Decay Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-based-decay-scheduling">
     Step-based Decay Scheduling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adaptative-learning-rate">
   Adaptative Learning Rate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#momentum-optimization">
     Momentum Optimization
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Varying the Learning Rate</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivations">
   Motivations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-rate-schedulers">
   Learning Rate Schedulers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#power-scheduling">
     Power Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#time-based-decay-scheduling">
     Time-Based Decay Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-decay-scheduling">
     Exponential Decay Scheduling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#step-based-decay-scheduling">
     Step-based Decay Scheduling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adaptative-learning-rate">
   Adaptative Learning Rate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#momentum-optimization">
     Momentum Optimization
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="varying-the-learning-rate">
<h1>Varying the Learning Rate<a class="headerlink" href="#varying-the-learning-rate" title="Permalink to this headline">#</a></h1>
<section id="motivations">
<h2>Motivations<a class="headerlink" href="#motivations" title="Permalink to this headline">#</a></h2>
<p>We saw in previous lectures that the Gradient Descent algorithm updates the parameters, or weights, in the form:</p>
<div class="math notranslate nohighlight" id="equation-paramupdate">
<span class="eqno">(110)<a class="headerlink" href="#equation-paramupdate" title="Permalink to this equation">#</a></span>\[W_j \quad \leftarrow \quad W_j -\alpha \frac{\partial}{\partial W_j} J\left(\boldsymbol{W}\right) \;   \;   \;  \;   \;   \; \forall j \in [0..n]\]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Recall that the learning rate <span class="math notranslate nohighlight">\(\alpha\)</span> is the hyperparameter defining the step size on the parameters at each update.</p>
</aside>
<p>The learning rate <span class="math notranslate nohighlight">\(\alpha\)</span> is kept constant through the whole process of Gradient Descent.</p>
<p>But we saw that the model’s performance could be drastrically affected by the learning rate value; if too small the descent would take ages to converge, too big it could explode and not converge at all. How to properly choose this crucial hyperparameter?</p>
<p>In the florishing epoch (pun intended) of deep learning, new optimization techniques have emerged. The two most influencial families are <strong>Learning Rate Schedulers</strong> and <strong>Adaptative Learning Rates</strong>.</p>
</section>
<section id="learning-rate-schedulers">
<h2>Learning Rate Schedulers<a class="headerlink" href="#learning-rate-schedulers" title="Permalink to this headline">#</a></h2>
<div class="proof definition admonition" id="learningratescheduledef">
<p class="admonition-title"><span class="caption-number">Definition 67 </span></p>
<section class="definition-content" id="proof-content">
<p>In a training procedure involving a learning rate, a <strong>learning rate scheduler</strong> is a method consisting of modifying the learning rate at the beginning of each iteration.</p>
<p>It uses a <strong>schedule function</strong>, which takes the current learning rate as input, along with a ‘time’ parameter linked with the increasing number of iterations, to output a new learning rate.</p>
<p>The updated learning rate is used in the optimizer.</p>
</section>
</div><p>Schedule refers to a timing; here it is the index number of the epoch, or iteration, that is incremented over time, i.e. the duration of the training.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>What is the difference between epoch, batches and iteration?</strong></p>
<p>As we saw in Lecture 2 Section <a class="reference internal" href="../week1/warmup_1D_linRegGD.html#warmup-linreggd-gradientdescent"><span class="std std-ref">Gradient Descent</span></a>, an epoch is equivalent to the number of times the algorithm scans the entire data. It is a pass seeing the entire dataset. The batch size being the number of training samples, an iteration will be the number of batches needed to complete one epoch.
Example: if we have 1000 training samples splits in batches of size 250 each, then it will take 4 iterations to complete one epoch.</p>
</div>
<div class="seealso admonition">
<p class="admonition-title">Question</p>
<p>How should the learning rate vary? Should it increase? Decrease? Both?</p>
</div>
<p>Below are common learning schedules.</p>
<section id="power-scheduling">
<h3>Power Scheduling<a class="headerlink" href="#power-scheduling" title="Permalink to this headline">#</a></h3>
<p>The learning rate is modified according to:</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The <span class="math notranslate nohighlight">\(t\)</span> argument is the iteration integer, akin to a time yet the value are usually the iteration and/or epoch indices.</p>
</aside>
<div class="math notranslate nohighlight" id="equation-powerscheduleeq">
<span class="eqno">(111)<a class="headerlink" href="#equation-powerscheduleeq" title="Permalink to this equation">#</a></span>\[\alpha(t) = \frac{\alpha_0}{\left(1 + \frac{t}{s}\right)^c} \; ,\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_0\)</span> is the initial learning rate. The steps <span class="math notranslate nohighlight">\(s\)</span> and power <span class="math notranslate nohighlight">\(c\)</span> (usually 1) are hyperparameters. The learning rate drops at each step; e.g. after <span class="math notranslate nohighlight">\(s\)</span> steps it is divided by 2 (assuming <span class="math notranslate nohighlight">\(c\)</span> = 1).</p>
</section>
<section id="time-based-decay-scheduling">
<h3>Time-Based Decay Scheduling<a class="headerlink" href="#time-based-decay-scheduling" title="Permalink to this headline">#</a></h3>
<p>The time-based learning rate scheduler is often the standard (e.g. the default implementation in Keras library). It is controlled by a decay parameter <span class="math notranslate nohighlight">\(d = \frac{\alpha_0}{N}\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of epochs. It is similar (a particular case even) to the power scheduling:</p>
<div class="math notranslate nohighlight" id="equation-timebaseddecayeq">
<span class="eqno">(112)<a class="headerlink" href="#equation-timebaseddecayeq" title="Permalink to this equation">#</a></span>\[\alpha(t) = \alpha_0 \times \frac{1}{1 + d \times t} \]</div>
<p>As compared to a linear decrease, time-based decay causes learning rate to decrease faster upon training start, and much slower later (see graph below).</p>
</section>
<section id="exponential-decay-scheduling">
<h3>Exponential Decay Scheduling<a class="headerlink" href="#exponential-decay-scheduling" title="Permalink to this headline">#</a></h3>
<p>The exponential decay is defined as:</p>
<div class="math notranslate nohighlight">
\[\alpha(t) = \alpha_0 \times 0.1^{-t/s} \; ,\]</div>
<p>which will get the learning rate to decrease faster upon training start, and much slower later.</p>
<figure class="align-default" id="lec08-2-lr-decays">
<a class="reference internal image-reference" href="../_images/lec08_2_lr_decays.png"><img alt="../_images/lec08_2_lr_decays.png" src="../_images/lec08_2_lr_decays.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 56 </span><span class="caption-text">. Evolution of the learning rate vs ‘time’ as the number of epochs for three schedulers: linear decrease, time-based decay and exponential decay.<br />
<sub>Image: neptune.ai</sub></span><a class="headerlink" href="#lec08-2-lr-decays" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="step-based-decay-scheduling">
<h3>Step-based Decay Scheduling<a class="headerlink" href="#step-based-decay-scheduling" title="Permalink to this headline">#</a></h3>
<p>Also called piecewise constant scheduling, this approach first uses of a constant learning rate for a given number of epochs and then the learning rate is reduced:</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>The floor function <code class="docutils literal notranslate"><span class="pre">floor(x)</span></code> or <span class="math notranslate nohighlight">\(\lfloor x \rfloor\)</span> returns the greatest integer less than or equal to <span class="math notranslate nohighlight">\(x\)</span>.</p>
</aside>
<div class="math notranslate nohighlight">
\[\alpha(t) = \alpha_0 \times e^{ \left \lfloor - \frac{t}{s} \right \rfloor }\]</div>
<figure class="align-default" id="lec08-2-lr-step">
<a class="reference internal image-reference" href="../_images/lec08_2_lr_step.png"><img alt="../_images/lec08_2_lr_step.png" src="../_images/lec08_2_lr_step.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 57 </span><span class="caption-text">. Step-based learning rate decay.<br />
<sub>Image: neptune.ai</sub></span><a class="headerlink" href="#lec08-2-lr-step" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="seealso admonition">
<p class="admonition-title">Learn More</p>
<ul class="simple">
<li><p>Guide to Pytorch Learning Rate Scheduling on <a class="reference external" href="https://www.kaggle.com/code/isbhargav/guide-to-pytorch-learning-rate-scheduling/notebook">Kaggle</a></p></li>
</ul>
</div>
</section>
</section>
<section id="adaptative-learning-rate">
<h2>Adaptative Learning Rate<a class="headerlink" href="#adaptative-learning-rate" title="Permalink to this headline">#</a></h2>
<p>An algorithm combining Stochastic Gradient Descent with a learning rate schedule would have been considered close to the state-of-the-art before… the arrival of much faster methods called adaptative optimizers. Instead of a separate scheduler, the optimization of the learning rate is directly embedded in the optimizer. These optimizers approximate the gradient using model internal feedback. In other words, they incorporate the history in the weight update. Huge advantage: they are almost parameter-free.</p>
<div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 68 </span></p>
<section class="definition-content" id="proof-content">
<p>An <strong>Adaptative Learning Rate</strong> refers to varying the learning rate using feedback from the model itself.</p>
</section>
</div><p>As the variation of the learning rate is done by the optimizer, adaptative learning rates and adaptative optimizers are equivalent terms.</p>
<p>Below are brief descriptions of the most popular adaptative optimizers.</p>
<section id="momentum-optimization">
<h3>Momentum Optimization<a class="headerlink" href="#momentum-optimization" title="Permalink to this headline">#</a></h3>
<p>In physics, the momentum <span class="math notranslate nohighlight">\(\boldsymbol{p}\)</span> is a vector obtained by taking the product of the mass and velocity of an object. It quantifies motion. In computing science, momentum refers to the direction and speed at which the parameters move - via iterative updates - through the parameter space.</p>
<div class="seealso admonition">
<p class="admonition-title">Learn More</p>
<p>Let’s go to the source!<br />
The paper introducing Adam in 2015: <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></p>
</div>
<p>================</p>
<p>simulated annealing</p>
<p>https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./week2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="DL_stochGD.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Stochastic Gradient Descent</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="DL_paramHyper.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Hyperparameters in DL</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Claire David<br/>
  
      &copy; Copyright 2022.<br/>
    <div class="extra_footer">
      <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>